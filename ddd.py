import nltk

from nltk.book import *

print( "===" )
print( "text1 = ", text1 )
print( "===" )
print( "text2 = ", text2 )
print( "===" )
print( "concordance = ", text1.concordance("monstrous") )
print( "===" )
print( "similar = ", text1.similar("monstrous") )
print( "===" )
print( "similar = ", text2.similar("monstrous") )
print( "===" )
print( "very = ", text2.common_contexts( ["monstrous", "very"] ) )
print( "===" )
print ( "dispersian_plot =" )
text4.dispersion_plot(["citizens", "democracy", "freedom", "duties", "America"])
print( "===" )
#
# not available in Python version 3.x
#
# print ( "generate =" )
# text3.generate()
print( "===" )
print( "len( text( 3 ) ) = ", len( text3 ) )
print( "===" )
print( "sorted( set( text3 ) ) = ", sorted( set( text3 ) ) )
print( "===" )
print( "len(set(text3)) / len(text3)", len( set( text3 ) ) / len( text3 ) )
print( "===" )
print( "text3.count('smote') = ", text3.count( "smote" ) )
print( "===" )
print( " def lexical_diversity(text):" )
print( "  return len( set( text ) ) / len( text )" )
print( "===" )
print( "def percentage(count, total):" )
print( " return 100 * count / total" )
print( "===" )
sent = ['word1', 'word2', 'word3', 'word4', 'word5', 'word6', 'word7', 'word8', 'word9', 'word10']
print( sent )
print( "===" )
print( "sent[ : 3 ] = ", sent[ : 3 ] )
print( "===" )
print( "sent[ 0 : 3 ] = ", sent[ 0 : 3 ] )
print( "===" )
print( "===" )
print( "===" )
print( "===" )
print( "===" )
print( "===" )
print( "===" )
print( "===" )
print( "===" )
print( "===" )
print( "===" )
print( "===" )
print( "===" )
print( "===" )
print( "===" )


